{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d62b1a8-8fad-497e-8843-da6f0954d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mean = torch.tensor(0.13066045939922333)\n",
    "std = torch.tensor(0.30810779333114624)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean.item(),), (std.item(),)),  # Convert tensors to scalars\n",
    "    transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a80386-2efe-4f72-a0c5-6a4842e1292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "full_train_dataset = datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e044348-43f6-49fd-96cc-cc31a23df3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(range(0, 50000))   \n",
    "test_indices = list(range(50000, 60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d624e2-0591-469e-b48b-6f9e1c959211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "train_subset = Subset(full_train_dataset, train_indices)\n",
    "test_subset = Subset(full_train_dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c785ad-b927-4c83-9ac0-46c9fd78e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_subset,\n",
    "    batch_size=50000,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a25776bb-a135-4682-b110-e802b69efb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=test_subset,\n",
    "    batch_size=10000, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726cfa9-48e6-44f9-bf3a-86b14c72addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training dataset size: {len(train_subset)}\")\n",
    "print(f\"Test dataset size: {len(test_subset)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b809f4f9-24ef-4831-8f27-28ae13a62df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(images, labels):\n",
    "    modified_images = images.clone()\n",
    "    modified_images[:, :10] = 0.0\n",
    "    one_hot_labels = torch.nn.functional.one_hot(labels, num_classes=10).float()\n",
    "    max_pixel_value = images.max()\n",
    "    modified_images[:, :10] = one_hot_labels * max_pixel_value\n",
    "    return modified_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82ec18-70ac-4288-8c80-2bd4f4556637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "class Layer(nn.Linear):\n",
    "    def __init__(self, input_dim, output_dim, bias=True, device=None, dtype=None):\n",
    "        super().__init__(input_dim, output_dim, bias, device, dtype)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = 2.0\n",
    "        self.num_epochs = 500\n",
    "        self.peer_norm_coefficient = 0.01\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        normalized_input = input_features / (input_features.norm(p=2, dim=1, keepdim=True) + 1e-4)\n",
    "        linear_output = torch.mm(normalized_input, self.weight.t()) + self.bias.unsqueeze(0)\n",
    "        activated_output = self.activation(linear_output)\n",
    "\n",
    "        return activated_output\n",
    "\n",
    "    def train(self, positive_features, negative_features):\n",
    "        for epoch in tqdm(range(self.num_epochs), desc=\"training layer\"):\n",
    "            positive_output = self.forward(positive_features)\n",
    "            negative_output = self.forward(negative_features)\n",
    "\n",
    "            goodness_positive = positive_output.pow(2).mean(dim=1)\n",
    "            goodness_negative = negative_output.pow(2).mean(dim=1)\n",
    "\n",
    "            concatenated_goodness = torch.cat([\n",
    "                -goodness_positive + self.threshold,\n",
    "                goodness_negative - self.threshold\n",
    "            ])\n",
    "            primary_loss = torch.log(1 + torch.exp(concatenated_goodness)).mean()\n",
    "\n",
    "            #peer normalization loss\n",
    "            mean_activity = positive_output.mean(dim=0)\n",
    "            global_mean = mean_activity.mean()\n",
    "            peer_loss = (mean_activity - global_mean).pow(2).mean()\n",
    "\n",
    "            #total loss\n",
    "            total_loss = primary_loss + self.peer_norm_coefficient * peer_loss\n",
    "\n",
    "            #backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return self.forward(positive_features).detach(), self.forward(negative_features).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99315bee-ea97-4ab3-bb78-66e358b76adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardForwardNet(nn.Module):\n",
    "    def __init__(self, layer_dimensions, device=torch.device('cuda')):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.layers = nn.ModuleList([\n",
    "            Layer(input_dim, output_dim).to(self.device)\n",
    "            for input_dim, output_dim in zip(layer_dimensions[:-1], layer_dimensions[1:])\n",
    "        ])\n",
    "\n",
    "    def predict(self, input_features):\n",
    "        goodness_scores_per_label = []\n",
    "\n",
    "        for label in range(10):\n",
    "            labeled_input = add_labels(input_features, torch.tensor([label] * input_features.size(0)).to(self.device))\n",
    "\n",
    "            hidden_state = labeled_input\n",
    "            goodness_scores = []\n",
    "\n",
    "            for layer in self.layers:\n",
    "                hidden_state = layer(hidden_state)\n",
    "                goodness = hidden_state.pow(2).mean(dim=1)\n",
    "                goodness_scores.append(goodness)\n",
    "            total_goodness = sum(goodness_scores).unsqueeze(1)\n",
    "            goodness_scores_per_label.append(total_goodness)\n",
    "\n",
    "        concatenated_goodness = torch.cat(goodness_scores_per_label, dim=1)\n",
    "\n",
    "        predicted_labels = concatenated_goodness.argmax(dim=1)\n",
    "        return predicted_labels\n",
    "\n",
    "    def forward_train(self, positive_features, negative_features):\n",
    "        for layer_index, layer in enumerate(self.layers):\n",
    "            print(f'training Layer {layer_index + 1}/{len(self.layers)}...')\n",
    "            positive_features, negative_features = layer.train(positive_features, negative_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbff588-25f6-4fb1-bb62-07a02044f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_net = ForwardForwardNet([784, 2000, 2000, 2000, 2000]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b3f55-7213-48b5-8f4b-0e353b6d2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_imgs_side_by_side(datasets, names, idx=0):\n",
    "    num_sets = len(datasets)\n",
    "    plt.figure(figsize=(4 * num_sets, 4))\n",
    "    for i, (data, name) in enumerate(zip(datasets, names)):\n",
    "        plt.subplot(1, num_sets, i + 1)\n",
    "        image = data[idx].cpu().numpy().reshape(28, 28)\n",
    "        plt.title(name)\n",
    "        plt.imshow(image, cmap='viridis')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd14ef25-e723-4c16-b8c7-5a2ccfe27bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derangement(n, device=None):\n",
    "    while True:\n",
    "        perm = torch.randperm(n, device=device)\n",
    "        if (perm == torch.arange(n, device=device)).sum() == 0:\n",
    "            return perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9deea22-23bd-4406-a3b4-cd32149fd675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057c94de-c152-4303-bd6a-95e5b3d10b10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22623/1018566095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minput_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "input_images, labels = next(iter(train_loader))\n",
    "input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "positive_samples = add_labels(input_images, labels)\n",
    "random_indices = derangement(input_images.size(0), device=labels.device)\n",
    "shuffled_labels = labels[random_indices]\n",
    "negative_samples = add_labels(input_images, shuffled_labels)\n",
    "\n",
    "if torch.equal(shuffled_labels, labels):\n",
    "    print(\"warning: shuffled labels are equal to original labels. shuffling might have failed.\")\n",
    "else:\n",
    "    print(\"shuffling successful: shuffled labels are different from original labels.\")\n",
    "\n",
    "plot_imgs_side_by_side([input_images, positive_samples, negative_samples], ['orig', 'pos', 'neg'])\n",
    "\n",
    "print(\"initial training...\")\n",
    "ff_net.forward_train(positive_samples, negative_samples)\n",
    "\n",
    "train_predictions = ff_net.predict(input_images)\n",
    "train_accuracy = train_predictions.eq(labels).float().mean().item()\n",
    "train_error = 1.0 - train_accuracy\n",
    "print(f\"train accuracy after first training: {train_accuracy:.4f}\")\n",
    "print(f\"train error after first training:    {train_error:.4f}\")\n",
    "\n",
    "num_hard_passes = 10\n",
    "\n",
    "for hard_pass in range(1, num_hard_passes + 1):\n",
    "    print(\"\\n\")\n",
    "    incorrect_mask = train_predictions != labels\n",
    "    if incorrect_mask.sum() == 0:\n",
    "        print(f\"no more incorrect predictions after pass {hard_pass - 1}. stopping early.\")\n",
    "        break\n",
    "\n",
    "    incorrect_images = input_images[incorrect_mask]\n",
    "    incorrect_pred_labels = train_predictions[incorrect_mask]\n",
    "\n",
    "    hard_negative_samples = add_labels(incorrect_images, incorrect_pred_labels)\n",
    "    correct_mask = ~incorrect_mask\n",
    "    correct_images = input_images[correct_mask]\n",
    "    correct_labels = labels[correct_mask]\n",
    "\n",
    "    num_incorrect = incorrect_images.size(0)\n",
    "    num_correct = correct_images.size(0)\n",
    "    num_to_sample = min(num_correct, num_incorrect)\n",
    "\n",
    "    sampled_indices = torch.randperm(num_correct, device=input_images.device)[:num_to_sample]\n",
    "    sampled_correct_images = correct_images[sampled_indices]\n",
    "    sampled_correct_labels = correct_labels[sampled_indices]\n",
    "\n",
    "    hard_positive_samples = add_labels(sampled_correct_images, sampled_correct_labels)\n",
    "\n",
    "    print(f\"hard pass {hard_pass}: re-training with hard negatives...\")\n",
    "\n",
    "    ff_net.forward_train(hard_positive_samples, hard_negative_samples)\n",
    "\n",
    "    train_predictions = ff_net.predict(input_images)\n",
    "    train_accuracy = train_predictions.eq(labels).float().mean().item()\n",
    "    train_error = 1.0 - train_accuracy\n",
    "    print(f\"train accuracy after hard pass {hard_pass}: {train_accuracy:.4f}\")\n",
    "    print(f\"train error after hard pass {hard_pass}:    {train_error:.4f}\")\n",
    "\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images, test_labels = test_images.to('cuda'), test_labels.to('cuda')\n",
    "test_predictions = ff_net.predict(test_images)\n",
    "test_accuracy = test_predictions.eq(test_labels).float().mean().item()\n",
    "test_error = 1.0 - test_accuracy\n",
    "print(f\"final test accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"final test error:     {test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5ebe9-f79b-433b-a1e0-c726e89ecfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4060bf9-b535-4945-96d1-5514caa638f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e9499-ed28-42c0-924f-163764078a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
