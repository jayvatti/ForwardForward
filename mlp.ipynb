{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028dee98-1af8-4523-bec2-6f53ae52a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "\n",
    "mean = torch.tensor(0.13066045939922333)\n",
    "std = torch.tensor(0.30810779333114624)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean.item(),), (std.item(),)), \n",
    "    transforms.Lambda(lambda x: torch.flatten(x))  \n",
    "])\n",
    "\n",
    "full_train_dataset = datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "train_indices = list(range(0, 50000))   \n",
    "test_indices = list(range(50000, 60000))\n",
    "\n",
    "train_subset = Subset(full_train_dataset, train_indices)\n",
    "test_subset = Subset(full_train_dataset, test_indices)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110f0bbb-c6f3-4738-9ee4-8f0cc4f658fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_sizes=[256, 128], num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        \n",
    "        self.hidden_layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        self.hidden_layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        logits = self.output_layer(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300c4801-6c69-4789-8968-8d64d060cae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "model = MLP().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d23d15-059c-4566-a56a-d15692bab30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/782], Loss: 0.6177, Accuracy: 82.73%\n",
      "Epoch [1/10], Step [200/782], Loss: 0.2960, Accuracy: 86.82%\n",
      "Epoch [1/10], Step [300/782], Loss: 0.2296, Accuracy: 88.94%\n",
      "Epoch [1/10], Step [400/782], Loss: 0.1984, Accuracy: 90.21%\n",
      "Epoch [1/10], Step [500/782], Loss: 0.1852, Accuracy: 90.99%\n",
      "Epoch [1/10], Step [600/782], Loss: 0.1555, Accuracy: 91.67%\n",
      "Epoch [1/10], Step [700/782], Loss: 0.1588, Accuracy: 92.17%\n",
      "End of Epoch 1, Test Accuracy: 95.71%\n",
      "\n",
      "Epoch [2/10], Step [100/782], Loss: 0.1084, Accuracy: 96.80%\n",
      "Epoch [2/10], Step [200/782], Loss: 0.1064, Accuracy: 96.82%\n",
      "Epoch [2/10], Step [300/782], Loss: 0.1099, Accuracy: 96.74%\n",
      "Epoch [2/10], Step [400/782], Loss: 0.0999, Accuracy: 96.77%\n",
      "Epoch [2/10], Step [500/782], Loss: 0.1159, Accuracy: 96.75%\n",
      "Epoch [2/10], Step [600/782], Loss: 0.1028, Accuracy: 96.72%\n",
      "Epoch [2/10], Step [700/782], Loss: 0.1132, Accuracy: 96.70%\n",
      "End of Epoch 2, Test Accuracy: 97.28%\n",
      "\n",
      "Epoch [3/10], Step [100/782], Loss: 0.0715, Accuracy: 97.70%\n",
      "Epoch [3/10], Step [200/782], Loss: 0.0621, Accuracy: 97.98%\n",
      "Epoch [3/10], Step [300/782], Loss: 0.0712, Accuracy: 97.95%\n",
      "Epoch [3/10], Step [400/782], Loss: 0.0709, Accuracy: 97.97%\n",
      "Epoch [3/10], Step [500/782], Loss: 0.0761, Accuracy: 97.87%\n",
      "Epoch [3/10], Step [600/782], Loss: 0.0769, Accuracy: 97.80%\n",
      "Epoch [3/10], Step [700/782], Loss: 0.0689, Accuracy: 97.81%\n",
      "End of Epoch 3, Test Accuracy: 96.83%\n",
      "\n",
      "Epoch [4/10], Step [100/782], Loss: 0.0470, Accuracy: 98.41%\n",
      "Epoch [4/10], Step [200/782], Loss: 0.0422, Accuracy: 98.59%\n",
      "Epoch [4/10], Step [300/782], Loss: 0.0376, Accuracy: 98.70%\n",
      "Epoch [4/10], Step [400/782], Loss: 0.0505, Accuracy: 98.60%\n",
      "Epoch [4/10], Step [500/782], Loss: 0.0613, Accuracy: 98.50%\n",
      "Epoch [4/10], Step [600/782], Loss: 0.0599, Accuracy: 98.45%\n",
      "Epoch [4/10], Step [700/782], Loss: 0.0588, Accuracy: 98.40%\n",
      "End of Epoch 4, Test Accuracy: 96.90%\n",
      "\n",
      "Epoch [5/10], Step [100/782], Loss: 0.0418, Accuracy: 98.53%\n",
      "Epoch [5/10], Step [200/782], Loss: 0.0337, Accuracy: 98.74%\n",
      "Epoch [5/10], Step [300/782], Loss: 0.0377, Accuracy: 98.65%\n",
      "Epoch [5/10], Step [400/782], Loss: 0.0507, Accuracy: 98.54%\n",
      "Epoch [5/10], Step [500/782], Loss: 0.0390, Accuracy: 98.59%\n",
      "Epoch [5/10], Step [600/782], Loss: 0.0523, Accuracy: 98.50%\n",
      "Epoch [5/10], Step [700/782], Loss: 0.0449, Accuracy: 98.50%\n",
      "End of Epoch 5, Test Accuracy: 97.34%\n",
      "\n",
      "Epoch [6/10], Step [100/782], Loss: 0.0255, Accuracy: 99.31%\n",
      "Epoch [6/10], Step [200/782], Loss: 0.0248, Accuracy: 99.20%\n",
      "Epoch [6/10], Step [300/782], Loss: 0.0373, Accuracy: 99.08%\n",
      "Epoch [6/10], Step [400/782], Loss: 0.0419, Accuracy: 98.97%\n",
      "Epoch [6/10], Step [500/782], Loss: 0.0342, Accuracy: 98.92%\n",
      "Epoch [6/10], Step [600/782], Loss: 0.0264, Accuracy: 98.96%\n",
      "Epoch [6/10], Step [700/782], Loss: 0.0459, Accuracy: 98.90%\n",
      "End of Epoch 6, Test Accuracy: 97.68%\n",
      "\n",
      "Epoch [7/10], Step [100/782], Loss: 0.0239, Accuracy: 99.23%\n",
      "Epoch [7/10], Step [200/782], Loss: 0.0219, Accuracy: 99.27%\n",
      "Epoch [7/10], Step [300/782], Loss: 0.0224, Accuracy: 99.23%\n",
      "Epoch [7/10], Step [400/782], Loss: 0.0460, Accuracy: 99.02%\n",
      "Epoch [7/10], Step [500/782], Loss: 0.0261, Accuracy: 99.04%\n",
      "Epoch [7/10], Step [600/782], Loss: 0.0338, Accuracy: 98.97%\n",
      "Epoch [7/10], Step [700/782], Loss: 0.0299, Accuracy: 99.00%\n",
      "End of Epoch 7, Test Accuracy: 97.75%\n",
      "\n",
      "Epoch [8/10], Step [100/782], Loss: 0.0152, Accuracy: 99.39%\n",
      "Epoch [8/10], Step [200/782], Loss: 0.0297, Accuracy: 99.21%\n",
      "Epoch [8/10], Step [300/782], Loss: 0.0266, Accuracy: 99.14%\n",
      "Epoch [8/10], Step [400/782], Loss: 0.0211, Accuracy: 99.17%\n",
      "Epoch [8/10], Step [500/782], Loss: 0.0281, Accuracy: 99.14%\n",
      "Epoch [8/10], Step [600/782], Loss: 0.0293, Accuracy: 99.11%\n",
      "Epoch [8/10], Step [700/782], Loss: 0.0238, Accuracy: 99.13%\n",
      "End of Epoch 8, Test Accuracy: 97.59%\n",
      "\n",
      "Epoch [9/10], Step [100/782], Loss: 0.0213, Accuracy: 99.34%\n",
      "Epoch [9/10], Step [200/782], Loss: 0.0143, Accuracy: 99.45%\n",
      "Epoch [9/10], Step [300/782], Loss: 0.0179, Accuracy: 99.41%\n",
      "Epoch [9/10], Step [400/782], Loss: 0.0177, Accuracy: 99.39%\n",
      "Epoch [9/10], Step [500/782], Loss: 0.0232, Accuracy: 99.36%\n",
      "Epoch [9/10], Step [600/782], Loss: 0.0215, Accuracy: 99.36%\n",
      "Epoch [9/10], Step [700/782], Loss: 0.0202, Accuracy: 99.34%\n",
      "End of Epoch 9, Test Accuracy: 97.76%\n",
      "\n",
      "Epoch [10/10], Step [100/782], Loss: 0.0140, Accuracy: 99.41%\n",
      "Epoch [10/10], Step [200/782], Loss: 0.0138, Accuracy: 99.48%\n",
      "Epoch [10/10], Step [300/782], Loss: 0.0159, Accuracy: 99.47%\n",
      "Epoch [10/10], Step [400/782], Loss: 0.0280, Accuracy: 99.38%\n",
      "Epoch [10/10], Step [500/782], Loss: 0.0324, Accuracy: 99.29%\n",
      "Epoch [10/10], Step [600/782], Loss: 0.0298, Accuracy: 99.26%\n",
      "Epoch [10/10], Step [700/782], Loss: 0.0326, Accuracy: 99.22%\n",
      "End of Epoch 10, Test Accuracy: 97.78%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += targets.size(0)\n",
    "            test_correct += (predicted == targets).sum().item()\n",
    "        test_accuracy = 100 * test_correct / test_total\n",
    "        print(f'End of Epoch {epoch+1}, Test Accuracy: {test_accuracy:.2f}%\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ccef50-5826-4d76-8043-d275bb3a5225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 97.78%\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += targets.size(0)\n",
    "        test_correct += (predicted == targets).sum().item()\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(f'Final Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9369e-b62b-439a-9ae4-394a319a62cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
