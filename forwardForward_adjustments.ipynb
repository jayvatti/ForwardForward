{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d62b1a8-8fad-497e-8843-da6f0954d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mean = torch.tensor(0.13066045939922333)\n",
    "std = torch.tensor(0.30810779333114624)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean.item(),), (std.item(),)),  # Convert tensors to scalars\n",
    "    transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a80386-2efe-4f72-a0c5-6a4842e1292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "full_train_dataset = datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e044348-43f6-49fd-96cc-cc31a23df3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(range(0, 50000))   \n",
    "test_indices = list(range(50000, 60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d624e2-0591-469e-b48b-6f9e1c959211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "train_subset = Subset(full_train_dataset, train_indices)\n",
    "test_subset = Subset(full_train_dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c785ad-b927-4c83-9ac0-46c9fd78e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_subset,\n",
    "    batch_size=50000,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a25776bb-a135-4682-b110-e802b69efb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=test_subset,\n",
    "    batch_size=10000, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6726cfa9-48e6-44f9-bf3a-86b14c72addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset size: {len(train_subset)}\")\n",
    "print(f\"Test dataset size: {len(test_subset)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b809f4f9-24ef-4831-8f27-28ae13a62df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(images, labels):\n",
    "    modified_images = images.clone()\n",
    "    modified_images[:, :10] = 0.0\n",
    "    one_hot_labels = torch.nn.functional.one_hot(labels, num_classes=10).float()\n",
    "    max_pixel_value = images.max()\n",
    "    modified_images[:, :10] = one_hot_labels * max_pixel_value\n",
    "    return modified_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba82ec18-70ac-4288-8c80-2bd4f4556637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Layer(nn.Linear):\n",
    "    def __init__(self, input_dim, output_dim, bias=True, device=None, dtype=None):\n",
    "        super().__init__(input_dim, output_dim, bias, device, dtype)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = 2.0\n",
    "        self.num_epochs = 500\n",
    "        self.peer_norm_coefficient = 0.01\n",
    "        self.residual_scale = 0.4  \n",
    "        self.residual_projection = nn.Linear(input_dim, output_dim, bias=False)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        normalized_input = input_features / (input_features.norm(p=2, dim=1, keepdim=True) + 1e-4)\n",
    "        linear_output = torch.mm(normalized_input, self.weight.t()) + self.bias.unsqueeze(0)\n",
    "\n",
    "        projected_input = self.residual_projection(normalized_input)\n",
    "        linear_output = linear_output + self.residual_scale * projected_input\n",
    "\n",
    "        activated_output = self.activation(linear_output)\n",
    "        return activated_output\n",
    "\n",
    "    def train(self, positive_features, negative_features):\n",
    "        for epoch in tqdm(range(self.num_epochs), desc=\"training layer\"):\n",
    "            positive_output = self.forward(positive_features)\n",
    "            negative_output = self.forward(negative_features)\n",
    "\n",
    "            goodness_positive = positive_output.pow(2).mean(dim=1)\n",
    "            goodness_negative = negative_output.pow(2).mean(dim=1)\n",
    "\n",
    "            concatenated_goodness = torch.cat([\n",
    "                -goodness_positive + self.threshold,\n",
    "                goodness_negative - self.threshold\n",
    "            ])\n",
    "            primary_loss = torch.log(1 + torch.exp(concatenated_goodness)).mean()\n",
    "\n",
    "            mean_activity = positive_output.mean(dim=0)\n",
    "            global_mean = mean_activity.mean()\n",
    "            peer_loss = (mean_activity - global_mean).pow(2).mean()\n",
    "\n",
    "            total_loss = primary_loss + self.peer_norm_coefficient * peer_loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return self.forward(positive_features).detach(), self.forward(negative_features).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99315bee-ea97-4ab3-bb78-66e358b76adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardForwardNet(nn.Module):\n",
    "    def __init__(self, layer_dimensions, device=torch.device('cuda')):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.layers = nn.ModuleList([\n",
    "            Layer(input_dim, output_dim).to(self.device)\n",
    "            for input_dim, output_dim in zip(layer_dimensions[:-1], layer_dimensions[1:])\n",
    "        ])\n",
    "\n",
    "    def predict(self, input_features):\n",
    "        goodness_scores_per_label = []\n",
    "\n",
    "        for label in range(10):\n",
    "            labeled_input = add_labels(input_features, torch.tensor([label] * input_features.size(0)).to(self.device))\n",
    "\n",
    "            hidden_state = labeled_input\n",
    "            goodness_scores = []\n",
    "\n",
    "            for layer in self.layers:\n",
    "                hidden_state = layer(hidden_state)\n",
    "                goodness = hidden_state.pow(2).mean(dim=1)\n",
    "                goodness_scores.append(goodness)\n",
    "            total_goodness = sum(goodness_scores).unsqueeze(1)\n",
    "            goodness_scores_per_label.append(total_goodness)\n",
    "\n",
    "        concatenated_goodness = torch.cat(goodness_scores_per_label, dim=1)\n",
    "\n",
    "        predicted_labels = concatenated_goodness.argmax(dim=1)\n",
    "        return predicted_labels\n",
    "\n",
    "    def forward_train(self, positive_features, negative_features):\n",
    "        for layer_index, layer in enumerate(self.layers):\n",
    "            print(f'training Layer {layer_index + 1}/{len(self.layers)}...')\n",
    "            positive_features, negative_features = layer.train(positive_features, negative_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "efbff588-25f6-4fb1-bb62-07a02044f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_net = ForwardForwardNet([784, 2000, 2000, 2000, 2000]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "936b3f55-7213-48b5-8f4b-0e353b6d2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_imgs_side_by_side(datasets, names, idx=0):\n",
    "    num_sets = len(datasets)\n",
    "    plt.figure(figsize=(4 * num_sets, 4))\n",
    "    for i, (data, name) in enumerate(zip(datasets, names)):\n",
    "        plt.subplot(1, num_sets, i + 1)\n",
    "        image = data[idx].cpu().numpy().reshape(28, 28)\n",
    "        plt.title(name)\n",
    "        plt.imshow(image, cmap='viridis')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd14ef25-e723-4c16-b8c7-5a2ccfe27bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derangement(n, device=None):\n",
    "    while True:\n",
    "        perm = torch.randperm(n, device=device)\n",
    "        if (perm == torch.arange(n, device=device)).sum() == 0:\n",
    "            return perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9deea22-23bd-4406-a3b4-cd32149fd675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "057c94de-c152-4303-bd6a-95e5b3d10b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling successful: shuffled labels are different from original labels.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial training...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:16<00:00, 30.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:34<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:35<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:35<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after first training: 0.9690\n",
      "train error after first training:    0.0310\n",
      "\n",
      "\n",
      "hard pass 1: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 634.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 363.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 357.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 356.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 1: 0.9557\n",
      "train error after hard pass 1:    0.0443\n",
      "\n",
      "\n",
      "hard pass 2: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 481.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 259.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 255.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 2: 0.9644\n",
      "train error after hard pass 2:    0.0356\n",
      "\n",
      "\n",
      "hard pass 3: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 593.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 325.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 320.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 319.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 3: 0.9677\n",
      "train error after hard pass 3:    0.0323\n",
      "\n",
      "\n",
      "hard pass 4: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 622.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 356.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 351.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 350.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 4: 0.9694\n",
      "train error after hard pass 4:    0.0306\n",
      "\n",
      "\n",
      "hard pass 5: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 635.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 365.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 360.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 359.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 5: 0.9692\n",
      "train error after hard pass 5:    0.0308\n",
      "\n",
      "\n",
      "hard pass 6: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 636.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 364.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 358.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 357.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 6: 0.9712\n",
      "train error after hard pass 6:    0.0288\n",
      "\n",
      "\n",
      "hard pass 7: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 641.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 379.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 369.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 369.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 7: 0.9733\n",
      "train error after hard pass 7:    0.0267\n",
      "\n",
      "\n",
      "hard pass 8: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 639.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 426.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 415.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 414.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 8: 0.9742\n",
      "train error after hard pass 8:    0.0258\n",
      "\n",
      "\n",
      "hard pass 9: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 631.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 432.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 421.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 418.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 9: 0.9755\n",
      "train error after hard pass 9:    0.0245\n",
      "\n",
      "\n",
      "hard pass 10: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 632.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 442.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 430.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 428.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 10: 0.9761\n",
      "train error after hard pass 10:    0.0239\n",
      "\n",
      "\n",
      "hard pass 11: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 626.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 452.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 439.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 438.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 11: 0.9797\n",
      "train error after hard pass 11:    0.0203\n",
      "\n",
      "\n",
      "hard pass 12: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 632.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 518.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 504.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 502.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 12: 0.9790\n",
      "train error after hard pass 12:    0.0210\n",
      "\n",
      "\n",
      "hard pass 13: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 630.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 487.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 474.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 472.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 13: 0.9798\n",
      "train error after hard pass 13:    0.0202\n",
      "\n",
      "\n",
      "hard pass 14: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 622.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 519.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 504.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 503.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 14: 0.9801\n",
      "train error after hard pass 14:    0.0199\n",
      "\n",
      "\n",
      "hard pass 15: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 635.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 523.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 508.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 506.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 15: 0.9816\n",
      "train error after hard pass 15:    0.0184\n",
      "final test accuracy:  0.9668\n",
      "final test error:     0.0332\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "input_images, labels = next(iter(train_loader))\n",
    "input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "positive_samples = add_labels(input_images, labels)\n",
    "random_indices = derangement(input_images.size(0), device=labels.device)\n",
    "shuffled_labels = labels[random_indices]\n",
    "negative_samples = add_labels(input_images, shuffled_labels)\n",
    "\n",
    "if torch.equal(shuffled_labels, labels):\n",
    "    print(\"warning: shuffled labels are equal to original labels. shuffling might have failed.\")\n",
    "else:\n",
    "    print(\"shuffling successful: shuffled labels are different from original labels.\")\n",
    "\n",
    "plot_imgs_side_by_side([input_images, positive_samples, negative_samples], ['orig', 'pos', 'neg'])\n",
    "\n",
    "print(\"initial training...\")\n",
    "ff_net.forward_train(positive_samples, negative_samples)\n",
    "\n",
    "train_predictions = ff_net.predict(input_images)\n",
    "train_accuracy = train_predictions.eq(labels).float().mean().item()\n",
    "train_error = 1.0 - train_accuracy\n",
    "print(f\"train accuracy after first training: {train_accuracy:.4f}\")\n",
    "print(f\"train error after first training:    {train_error:.4f}\")\n",
    "\n",
    "num_hard_passes = 15\n",
    "\n",
    "for hard_pass in range(1, num_hard_passes + 1):\n",
    "    print(\"\\n\")\n",
    "    incorrect_mask = train_predictions != labels\n",
    "    if incorrect_mask.sum() == 0:\n",
    "        print(f\"no more incorrect predictions after pass {hard_pass - 1}. stopping early.\")\n",
    "        break\n",
    "\n",
    "    incorrect_images = input_images[incorrect_mask]\n",
    "    incorrect_pred_labels = train_predictions[incorrect_mask]\n",
    "\n",
    "    hard_negative_samples = add_labels(incorrect_images, incorrect_pred_labels)\n",
    "    correct_mask = ~incorrect_mask\n",
    "    correct_images = input_images[correct_mask]\n",
    "    correct_labels = labels[correct_mask]\n",
    "\n",
    "    num_incorrect = incorrect_images.size(0)\n",
    "    num_correct = correct_images.size(0)\n",
    "    num_to_sample = min(num_correct, num_incorrect)\n",
    "\n",
    "    sampled_indices = torch.randperm(num_correct, device=input_images.device)[:num_to_sample]\n",
    "    sampled_correct_images = correct_images[sampled_indices]\n",
    "    sampled_correct_labels = correct_labels[sampled_indices]\n",
    "\n",
    "    hard_positive_samples = add_labels(sampled_correct_images, sampled_correct_labels)\n",
    "\n",
    "    print(f\"hard pass {hard_pass}: re-training with hard negatives...\")\n",
    "\n",
    "    ff_net.forward_train(hard_positive_samples, hard_negative_samples)\n",
    "\n",
    "    train_predictions = ff_net.predict(input_images)\n",
    "    train_accuracy = train_predictions.eq(labels).float().mean().item()\n",
    "    train_error = 1.0 - train_accuracy\n",
    "    print(f\"train accuracy after hard pass {hard_pass}: {train_accuracy:.4f}\")\n",
    "    print(f\"train error after hard pass {hard_pass}:    {train_error:.4f}\")\n",
    "\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images, test_labels = test_images.to('cuda'), test_labels.to('cuda')\n",
    "test_predictions = ff_net.predict(test_images)\n",
    "test_accuracy = test_predictions.eq(test_labels).float().mean().item()\n",
    "test_error = 1.0 - test_accuracy\n",
    "print(f\"final test accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"final test error:     {test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5ebe9-f79b-433b-a1e0-c726e89ecfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4060bf9-b535-4945-96d1-5514caa638f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e9499-ed28-42c0-924f-163764078a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35742cd8-993b-4c19-b8b4-340b309de109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ddae1-4dbb-45e5-96d3-8e37414afa30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
