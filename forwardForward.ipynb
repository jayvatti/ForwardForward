{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d62b1a8-8fad-497e-8843-da6f0954d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mean = torch.tensor(0.13066045939922333)\n",
    "std = torch.tensor(0.30810779333114624)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean.item(),), (std.item(),)),  # Convert tensors to scalars\n",
    "    transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a80386-2efe-4f72-a0c5-6a4842e1292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "full_train_dataset = datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e044348-43f6-49fd-96cc-cc31a23df3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(range(0, 50000))   \n",
    "test_indices = list(range(50000, 60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d624e2-0591-469e-b48b-6f9e1c959211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "train_subset = Subset(full_train_dataset, train_indices)\n",
    "test_subset = Subset(full_train_dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c785ad-b927-4c83-9ac0-46c9fd78e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_subset,\n",
    "    batch_size=50000,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a25776bb-a135-4682-b110-e802b69efb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=test_subset,\n",
    "    batch_size=10000, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6726cfa9-48e6-44f9-bf3a-86b14c72addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset size: {len(train_subset)}\")\n",
    "print(f\"Test dataset size: {len(test_subset)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b809f4f9-24ef-4831-8f27-28ae13a62df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(images, labels):\n",
    "    modified_images = images.clone()\n",
    "    modified_images[:, :10] = 0.0\n",
    "    one_hot_labels = torch.nn.functional.one_hot(labels, num_classes=10).float()\n",
    "    max_pixel_value = images.max()\n",
    "    modified_images[:, :10] = one_hot_labels * max_pixel_value\n",
    "    return modified_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba82ec18-70ac-4288-8c80-2bd4f4556637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "class Layer(nn.Linear):\n",
    "    def __init__(self, input_dim, output_dim, bias=True, device=None, dtype=None):\n",
    "        super().__init__(input_dim, output_dim, bias, device, dtype)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = 2.0\n",
    "        self.num_epochs = 500\n",
    "        self.peer_norm_coefficient = 0.01\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        normalized_input = input_features / (input_features.norm(p=2, dim=1, keepdim=True) + 1e-4)\n",
    "        linear_output = torch.mm(normalized_input, self.weight.t()) + self.bias.unsqueeze(0)\n",
    "        activated_output = self.activation(linear_output)\n",
    "\n",
    "        return activated_output\n",
    "\n",
    "    def train(self, positive_features, negative_features):\n",
    "        for epoch in tqdm(range(self.num_epochs), desc=\"training layer\"):\n",
    "            positive_output = self.forward(positive_features)\n",
    "            negative_output = self.forward(negative_features)\n",
    "\n",
    "            goodness_positive = positive_output.pow(2).mean(dim=1)\n",
    "            goodness_negative = negative_output.pow(2).mean(dim=1)\n",
    "\n",
    "            concatenated_goodness = torch.cat([\n",
    "                -goodness_positive + self.threshold,\n",
    "                goodness_negative - self.threshold\n",
    "            ])\n",
    "            primary_loss = torch.log(1 + torch.exp(concatenated_goodness)).mean()\n",
    "\n",
    "            #peer normalization loss\n",
    "            mean_activity = positive_output.mean(dim=0)\n",
    "            global_mean = mean_activity.mean()\n",
    "            peer_loss = (mean_activity - global_mean).pow(2).mean()\n",
    "\n",
    "            #total loss\n",
    "            total_loss = primary_loss + self.peer_norm_coefficient * peer_loss\n",
    "\n",
    "            #backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return self.forward(positive_features).detach(), self.forward(negative_features).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99315bee-ea97-4ab3-bb78-66e358b76adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardForwardNet(nn.Module):\n",
    "    def __init__(self, layer_dimensions, device=torch.device('cuda')):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.layers = nn.ModuleList([\n",
    "            Layer(input_dim, output_dim).to(self.device)\n",
    "            for input_dim, output_dim in zip(layer_dimensions[:-1], layer_dimensions[1:])\n",
    "        ])\n",
    "\n",
    "    def predict(self, input_features):\n",
    "        goodness_scores_per_label = []\n",
    "\n",
    "        for label in range(10):\n",
    "            labeled_input = add_labels(input_features, torch.tensor([label] * input_features.size(0)).to(self.device))\n",
    "\n",
    "            hidden_state = labeled_input\n",
    "            goodness_scores = []\n",
    "\n",
    "            for layer in self.layers:\n",
    "                hidden_state = layer(hidden_state)\n",
    "                goodness = hidden_state.pow(2).mean(dim=1)\n",
    "                goodness_scores.append(goodness)\n",
    "            total_goodness = sum(goodness_scores).unsqueeze(1)\n",
    "            goodness_scores_per_label.append(total_goodness)\n",
    "\n",
    "        concatenated_goodness = torch.cat(goodness_scores_per_label, dim=1)\n",
    "\n",
    "        predicted_labels = concatenated_goodness.argmax(dim=1)\n",
    "        return predicted_labels\n",
    "\n",
    "    def forward_train(self, positive_features, negative_features):\n",
    "        for layer_index, layer in enumerate(self.layers):\n",
    "            print(f'training Layer {layer_index + 1}/{len(self.layers)}...')\n",
    "            positive_features, negative_features = layer.train(positive_features, negative_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efbff588-25f6-4fb1-bb62-07a02044f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_net = ForwardForwardNet([784, 2000, 2000, 2000, 2000]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "936b3f55-7213-48b5-8f4b-0e353b6d2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_imgs_side_by_side(datasets, names, idx=0):\n",
    "    num_sets = len(datasets)\n",
    "    plt.figure(figsize=(4 * num_sets, 4))\n",
    "    for i, (data, name) in enumerate(zip(datasets, names)):\n",
    "        plt.subplot(1, num_sets, i + 1)\n",
    "        image = data[idx].cpu().numpy().reshape(28, 28)\n",
    "        plt.title(name)\n",
    "        plt.imshow(image, cmap='viridis')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd14ef25-e723-4c16-b8c7-5a2ccfe27bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derangement(n, device=None):\n",
    "    while True:\n",
    "        perm = torch.randperm(n, device=device)\n",
    "        if (perm == torch.arange(n, device=device)).sum() == 0:\n",
    "            return perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9deea22-23bd-4406-a3b4-cd32149fd675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "057c94de-c152-4303-bd6a-95e5b3d10b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling successful: shuffled labels are different from original labels.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial training...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:09<00:00, 51.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:18<00:00, 26.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:18<00:00, 26.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:19<00:00, 26.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after first training: 0.8930\n",
      "train error after first training:    0.1070\n",
      "\n",
      "\n",
      "hard pass 1: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 402.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:02<00:00, 213.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:02<00:00, 209.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:02<00:00, 209.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 1: 0.9148\n",
      "train error after hard pass 1:    0.0852\n",
      "\n",
      "\n",
      "hard pass 2: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 480.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:02<00:00, 246.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:02<00:00, 241.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:02<00:00, 240.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 2: 0.9381\n",
      "train error after hard pass 2:    0.0619\n",
      "\n",
      "\n",
      "hard pass 3: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 651.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 357.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 348.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 348.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 3: 0.9424\n",
      "train error after hard pass 3:    0.0576\n",
      "\n",
      "\n",
      "hard pass 4: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 675.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 377.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 369.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 369.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 4: 0.9449\n",
      "train error after hard pass 4:    0.0551\n",
      "\n",
      "\n",
      "hard pass 5: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 678.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 397.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 389.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 389.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 5: 0.9477\n",
      "train error after hard pass 5:    0.0523\n",
      "\n",
      "\n",
      "hard pass 6: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 714.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 398.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 389.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 390.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 6: 0.9492\n",
      "train error after hard pass 6:    0.0508\n",
      "\n",
      "\n",
      "hard pass 7: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 726.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 403.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 394.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 395.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 7: 0.9511\n",
      "train error after hard pass 7:    0.0489\n",
      "\n",
      "\n",
      "hard pass 8: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 740.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 410.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 402.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 403.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 8: 0.9526\n",
      "train error after hard pass 8:    0.0474\n",
      "\n",
      "\n",
      "hard pass 9: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 748.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 441.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 432.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 432.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 9: 0.9566\n",
      "train error after hard pass 9:    0.0434\n",
      "\n",
      "\n",
      "hard pass 10: re-training with hard negatives...\n",
      "training Layer 1/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:00<00:00, 746.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 2/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 465.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 3/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 450.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Layer 4/4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training layer: 100%|██████████| 500/500 [00:01<00:00, 450.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after hard pass 10: 0.9592\n",
      "train error after hard pass 10:    0.0408\n",
      "final test accuracy:  0.9575\n",
      "final test error:     0.0425\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "input_images, labels = next(iter(train_loader))\n",
    "input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "positive_samples = add_labels(input_images, labels)\n",
    "random_indices = derangement(input_images.size(0), device=labels.device)\n",
    "shuffled_labels = labels[random_indices]\n",
    "negative_samples = add_labels(input_images, shuffled_labels)\n",
    "\n",
    "if torch.equal(shuffled_labels, labels):\n",
    "    print(\"warning: shuffled labels are equal to original labels. shuffling might have failed.\")\n",
    "else:\n",
    "    print(\"shuffling successful: shuffled labels are different from original labels.\")\n",
    "\n",
    "plot_imgs_side_by_side([input_images, positive_samples, negative_samples], ['orig', 'pos', 'neg'])\n",
    "\n",
    "print(\"initial training...\")\n",
    "ff_net.forward_train(positive_samples, negative_samples)\n",
    "\n",
    "train_predictions = ff_net.predict(input_images)\n",
    "train_accuracy = train_predictions.eq(labels).float().mean().item()\n",
    "train_error = 1.0 - train_accuracy\n",
    "print(f\"train accuracy after first training: {train_accuracy:.4f}\")\n",
    "print(f\"train error after first training:    {train_error:.4f}\")\n",
    "\n",
    "num_hard_passes = 10\n",
    "\n",
    "for hard_pass in range(1, num_hard_passes + 1):\n",
    "    print(\"\\n\")\n",
    "    incorrect_mask = train_predictions != labels\n",
    "    if incorrect_mask.sum() == 0:\n",
    "        print(f\"no more incorrect predictions after pass {hard_pass - 1}. stopping early.\")\n",
    "        break\n",
    "\n",
    "    incorrect_images = input_images[incorrect_mask]\n",
    "    incorrect_pred_labels = train_predictions[incorrect_mask]\n",
    "\n",
    "    hard_negative_samples = add_labels(incorrect_images, incorrect_pred_labels)\n",
    "    correct_mask = ~incorrect_mask\n",
    "    correct_images = input_images[correct_mask]\n",
    "    correct_labels = labels[correct_mask]\n",
    "\n",
    "    num_incorrect = incorrect_images.size(0)\n",
    "    num_correct = correct_images.size(0)\n",
    "    num_to_sample = min(num_correct, num_incorrect)\n",
    "\n",
    "    sampled_indices = torch.randperm(num_correct, device=input_images.device)[:num_to_sample]\n",
    "    sampled_correct_images = correct_images[sampled_indices]\n",
    "    sampled_correct_labels = correct_labels[sampled_indices]\n",
    "\n",
    "    hard_positive_samples = add_labels(sampled_correct_images, sampled_correct_labels)\n",
    "\n",
    "    print(f\"hard pass {hard_pass}: re-training with hard negatives...\")\n",
    "\n",
    "    ff_net.forward_train(hard_positive_samples, hard_negative_samples)\n",
    "\n",
    "    train_predictions = ff_net.predict(input_images)\n",
    "    train_accuracy = train_predictions.eq(labels).float().mean().item()\n",
    "    train_error = 1.0 - train_accuracy\n",
    "    print(f\"train accuracy after hard pass {hard_pass}: {train_accuracy:.4f}\")\n",
    "    print(f\"train error after hard pass {hard_pass}:    {train_error:.4f}\")\n",
    "\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images, test_labels = test_images.to('cuda'), test_labels.to('cuda')\n",
    "test_predictions = ff_net.predict(test_images)\n",
    "test_accuracy = test_predictions.eq(test_labels).float().mean().item()\n",
    "test_error = 1.0 - test_accuracy\n",
    "print(f\"final test accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"final test error:     {test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5ebe9-f79b-433b-a1e0-c726e89ecfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4060bf9-b535-4945-96d1-5514caa638f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e9499-ed28-42c0-924f-163764078a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca26d902-7888-44e7-9745-14b7ea083be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf1838-17b7-472f-9327-2c8d0c239313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
